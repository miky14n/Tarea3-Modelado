{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a56b5f-7be2-4e15-a5d2-e6d70406a9f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Regresion import Regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de regresión\n",
    "\n",
    "Separamos los datos en conjunto de entrenamiento y conjunto de prueba. El 80% de los datos se utilizó para entrenar el modelo y el 20% restante para evaluarlo. Empleamos la función `train_test_split()` de sklearn, estableciendo `test_size=0.2` para obtener las proporciones 80%-20% de los datos. De esta forma separamos adecuadamente los datos en los conjuntos de entrenamiento y prueba para construir y evaluar el modelo de regresión..\n",
    "\n",
    "### Entrenamiento \n",
    "\n",
    "Para entrenar el modelo, consideramos 10 parámetros predictivos debido a que nos entregaron un coeficiente de correlación aceptable $ r > 0.5 $, se generaron 10 modelos secuencialmente.\n",
    ">\n",
    "El primer modelo se entrenó con el parámetro más relevante (mayor correlación), el segundo con los 2 parámetros más relevantes, y de esta manera se irán incluyendo los siguientes parámetros sucesivamente. Gracias a esto podremos evaluar el impacto de ir añadiendo parámetros para el entrenamiento y ver si el entrenamiento mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_ys(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    plt.title(\"Grafico de conjunto de entrenamiento vs conjunto de pruebas\")\n",
    "    plt.scatter(y_train, y_pred_train, label='Conjunto entrenamiento', alpha = 0.5)\n",
    "    plt.scatter(y_test, y_pred_test, label='Conjunto pruebas', alpha = 0.5)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def crear_modelo(X_train, X_test, y_train, y_test, graficar=False):\n",
    "    r = LinearRegression()\n",
    "    r.fit(X_train, y_train)\n",
    "    y_pred_train = r.predict(X_train)\n",
    "    r2_score_train = np.round(r2_score(y_train, y_pred_train),4)\n",
    "    y_pred_test = r.predict(X_test)\n",
    "    r2_score_test = np.round(r2_score(y_test, y_pred_test),4)\n",
    "    if graficar:\n",
    "        graficar_ys(y_train, y_pred_train, y_test, y_pred_test)\n",
    "        \n",
    "    formatted_coeficientes = [f'{coef:.4f}' for coef in r.coef_]\n",
    "    print(f'Coeficientes para {X_train.shape[1]} theta(s): {formatted_coeficientes}')\n",
    "    print(f'Coeficientes R2 para conjunto de entrenamiento es {r2_score_train}')\n",
    "    print(f'Coeficientes R2 para conjunto de pruebas es {r2_score_test}')\n",
    "    MSE = mean_squared_error(y_test, y_pred_test)\n",
    "    RMSE = math.sqrt(MSE)\n",
    "    print(f'Mean square error: {MSE}')\n",
    "    print(f'Root Mean square error: {RMSE}')\n",
    "    print('----------------------------------------------------------------------------------------------------------------')\n",
    "    return r, [r.coef_, r2_score_train, r2_score_test, MSE, RMSE]\n",
    "\n",
    "def crear_modelo_con_n_thetas(file_name, numbers_thetas, graficar=False):\n",
    "    modelos = []\n",
    "    metricas = []\n",
    "    df = pd.read_csv(file_name)\n",
    "    print(f'El modelo tiene las siguientes datos: ')\n",
    "    print(df.dtypes)\n",
    "    print(f'\\nTamaño dataframe: {df.shape}')\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df.iloc[:, 0 ]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    print(f'Tamaño de entrenamiento: {X_train.shape}\\t 80%')\n",
    "    print(f'Tamaño de pruebas: {X_test.shape}\\t\\t 20%')\n",
    "    print('----------------------------------------------------------------------------------------------------------------')\n",
    "    for i in range(1,numbers_thetas):\n",
    "        modelo, metrica_modelo = crear_modelo(X_train.iloc[:, :i ], X_test.iloc[:, :i ], y_train, y_test)\n",
    "        modelos.append(modelo)\n",
    "        metricas.append(metrica_modelo)\n",
    "    return modelos, metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasando los 10 parámetros mas significativos\n",
    "- $ \\theta_1 $ positioning\n",
    "- $ \\theta_2 $ finishing\n",
    "- $ \\theta_3 $ long_shots\n",
    "- $ \\theta_4 $ volleys\n",
    "- $ \\theta_5 $ ball_control\n",
    "- $ \\theta_6 $ shot_power\n",
    "- $ \\theta_7 $ free_kick_accuracy\n",
    "- $ \\theta_8 $ vision\n",
    "- $ \\theta_9 $ dribbling\n",
    "- $ \\theta_{10} $ curve\n",
    "\n",
    "Los datos que se le proporcionara para el entrenamiento son datos que ya fueron trabajados con limpieza y normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m modelos, metricas \u001b[38;5;241m=\u001b[39m \u001b[43mcrear_modelo_con_n_thetas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnormalized_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mcrear_modelo_con_n_thetas\u001b[0;34m(file_name, numbers_thetas, graficar)\u001b[0m\n\u001b[1;32m     30\u001b[0m modelos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m metricas \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(file_name)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEl modelo tiene las siguientes datos: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mdtypes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "modelos, metricas = crear_modelo_con_n_thetas('normalized_data.csv',11 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metricas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m R_train \u001b[38;5;241m=\u001b[39m [sublista[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sublista \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmetricas\u001b[49m]\n\u001b[1;32m      2\u001b[0m R_test \u001b[38;5;241m=\u001b[39m [sublista[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sublista \u001b[38;5;129;01min\u001b[39;00m metricas]\n\u001b[1;32m      3\u001b[0m x_ticks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metricas' is not defined"
     ]
    }
   ],
   "source": [
    "R_train = [sublista[1] for sublista in metricas]\n",
    "R_test = [sublista[2] for sublista in metricas]\n",
    "x_ticks = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "plt.plot(range(1,11), R_train, label='$R^2_{entrenamiento}$ ')\n",
    "plt.plot(range(1,11), R_test, label='$R^2_{pruebas}$ ')\n",
    "plt.title('Comportamiento de $R^2$ de acuerdo a cantidad de $\\\\theta_s$')\n",
    "plt.xlabel('$\\\\theta_s$')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xticks(x_ticks)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar como a mayor cantidad de parámetros va mejorando pero no es una mejora significativa, ya que solo alcanzan el valor de 0.66%, si va mejorando pero no es un coeficiente de correlación significativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metricas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m MSE \u001b[38;5;241m=\u001b[39m [sublista[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sublista \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmetricas\u001b[49m]\n\u001b[1;32m      2\u001b[0m RMSE \u001b[38;5;241m=\u001b[39m [sublista[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sublista \u001b[38;5;129;01min\u001b[39;00m metricas]\n\u001b[1;32m      4\u001b[0m x_ticks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metricas' is not defined"
     ]
    }
   ],
   "source": [
    "MSE = [sublista[3] for sublista in metricas]\n",
    "RMSE = [sublista[4] for sublista in metricas]\n",
    "\n",
    "x_ticks = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "plt.plot(range(1,11), RMSE, label='$RMSE$ ')\n",
    "#plt.plot(range(1,11), MSE, label='$MSE$ ')\n",
    "plt.title('Comportamiento de $MSE$ y $RMSE$ de acuerdo a cantidad de $\\\\theta_s$')\n",
    "plt.xlabel('$\\\\theta_s$')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xticks(x_ticks)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, al igual que con $ R^2 $, en este caso conforme aumentamos nuestros $\\theta_s$ tenemos mejores resultados.\n",
    ">\n",
    "En este caso, el error baja lo cual indica que nuestro modelo tiene una reacción favorable con la introducción de nuevos $\\theta_s$, algo a resaltar es que el mayor salto significativo se da cuando se trabaja con 3 parámetros y después de ello va descendiendo pero no tan abruptamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('normalized_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos apreciar que gracias a la normalizacion los datos no son dispersos, para esto se aggaro la columna que tiene mejor correlacion y la constrataremos con la columana que tiene la peor correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Regresion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# capturamos la mejor columna con respecto a la correlación, positioning           0.754793\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mRegresion\u001b[49m()\n\u001b[1;32m      3\u001b[0m r\u001b[38;5;241m.\u001b[39mfit(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositioning\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalties\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy())\n\u001b[1;32m      4\u001b[0m r\u001b[38;5;241m.\u001b[39mgraficar_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Regresion' is not defined"
     ]
    }
   ],
   "source": [
    "# capturamos la mejor columna con respecto a la correlación, positioning           0.754793\n",
    "r = Regresion()\n",
    "r.fit(data['positioning'].to_numpy().reshape(-1,1), data['penalties'].to_numpy())\n",
    "r.graficar_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una instancia de la Regresion\n",
    "Con la funcion fit agregamos como objetivo las columnas de 'positioning' y 'penalties'\n",
    "para luego graficar los datos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241m.\u001b[39mgraficar_j_3d()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r.graficar_j_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Regresion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#En este caso se captura el parametro con peor correlacion, curve                 0.651492\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[43mRegresion\u001b[49m()\n\u001b[1;32m      3\u001b[0m r2\u001b[38;5;241m.\u001b[39mfit(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurve\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenalties\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy())\n\u001b[1;32m      4\u001b[0m r2\u001b[38;5;241m.\u001b[39mgraficar_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Regresion' is not defined"
     ]
    }
   ],
   "source": [
    "#En este caso se captura el parametro con peor correlacion, curve                 0.651492\n",
    "r2 = Regresion()\n",
    "r2.fit(data['curve'].to_numpy().reshape(-1,1), data['penalties'].to_numpy())\n",
    "r2.graficar_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la funcion fit, hacemos objetivo a las Variables 'curve' y 'penalties' para luego\n",
    "graficar y visualizar la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241m.\u001b[39mgraficar_j_3d()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r.graficar_j_3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 848214964434792,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Práctica #3 - Regresión Lineal - Limpieza de Datos y Normalización",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
